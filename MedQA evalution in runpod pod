import pandas as pd
import ast
import os
import time
import requests
import json

# Define the API endpoint and your API key
api_endpoint = 'https://****-5000.proxy.runpod.net//v1/chat/completions'
api_key = '***'
model_name = 'google/gemma-2-27b-it'

# Define the headers for the request
headers = {
    "Authorization": f"Bearer {api_key}",
    "Content-Type": "application/json"
}

# File paths and configuration
input_file_path = r'C:\Users\ASUS\Desktop\amin\LLM quantization\datasets\medQA_sampled60.xlsx'
output_directory = r'C:\Users\ASUS\Desktop\amin\LLM quantization\experiment0_result\new_medqa\gemma2-27b'
safe_model_name = model_name.replace('/', '_')

# Ensure the output directory exists
os.makedirs(output_directory, exist_ok=True)

# Load the Excel file
df = pd.read_excel(input_file_path)

# Ensure the DataFrame has the required columns
if 'question' not in df.columns or 'options' not in df.columns:
    raise ValueError("The Excel file must contain 'question' and 'options' columns.")

# Define system prompts with associated numbers
user_prompts = [
    (1, "Answer the following question and select one option from the provided options."),
    (2, "Imagine you are a USMLE tutor facing this USMLE exam question. The goal of the USMLE is to assess a physician's knowledge. As an expert in the field, which answer would you choose?"),
    (3, "Answer the following question and select one option from the provided options. Please go through each option and detail your reasoning process behind evaluating each one to determine the correct answer."),
    (4, "Answer the following question and select one option from the provided options. Please select the correct answer and provide a justification for your choice."),
    (5, "Imagine you are a USMLE tutor and medical faculty member facing this USMLE exam question. The goal of the USMLE is to assess a physician's ability to apply knowledge, concepts, and principles crucial for providing safe and effective patient care. As an expert in the field, which answer would you choose and why?"),
    (6, "Imagine you are a USMLE tutor and medical faculty member facing this USMLE exam question. The goal of the USMLE is to assess a physician's ability to apply knowledge, concepts, and principles crucial for providing safe and effective patient care. As an expert in the field, rate your confidence level in the correctness of each of these options from 1 to 10, where 10 is most confident. Which option scores the highest?")
]

def create_prompt(question, options, system_prompt):
    try:
        options_dict = ast.literal_eval(options)
        options_str = "\n".join([f"{key}: {value}" for key, value in options_dict.items()])

        messages = [
            {"role": "user", "content": f"{system_prompt}: {question}\n\nOptions:\n{options_str}"}
        ]
        return messages
    except (ValueError, SyntaxError) as e:
        print(f"Error parsing options for question '{question}': {e}")
        return None

def generate_answer(messages, temperature, max_tokens):
    start_time = time.time()
    
    payload = {
        "model": model_name,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens
    }
    
    response = requests.post(api_endpoint, headers=headers, json=payload)
    end_time = time.time()
    inference_time = end_time - start_time
    
    if response.status_code == 200:
        data = response.json()
        return {
            'data': data,
            'final_answer': data['choices'][0]['message']['content'],
            'prompt_tokens': data['usage']['prompt_tokens'],
            'completion_tokens': data['usage']['completion_tokens'],
            'inference_time': inference_time
        }
    else:
        print(f"Error: {response.status_code}, {response.text}")
        return {
            'data': None,
            'final_answer': None,
            'prompt_tokens': None,
            'completion_tokens': None,
            'inference_time': inference_time
        }

def main():
    for prompt_number, system_prompt in user_prompts:
        for temperature in [0.1,0.5,1.0]:
            for max_tokens in [512,2048]:
                results = []
                metadata = {
                    'model_name': safe_model_name,
                    'prompt_number': prompt_number,
                    'max_tokens': max_tokens,
                    'temperature': temperature,
                }
                
                for index, row in df.iterrows():
                    question = row['question']
                    options = row['options']
                    
                    messages = create_prompt(question, options, system_prompt)
                    if messages is not None:
                        answer = generate_answer(messages, temperature, max_tokens)
                        
                        result = {
                            'question': question,
                            'options': options,
                            'system_prompt': system_prompt,
                            'temperature': temperature,
                            'max_tokens': max_tokens,
                            'final_answer': answer['final_answer'] if answer else None,
                            'response': answer['data'] if answer else None,
                            'Inference Time': answer['inference_time'] if answer else None,
                            'Input Token Count': answer['prompt_tokens'] if answer else None,
                            'Output Token Count': answer['completion_tokens'] if answer else None,
                            'metadata': metadata
                        }
                        results.append(result)

                        if (index + 1) % 3 == 0 or index == len(df) - 1:
                            result_df = pd.DataFrame(results)
                            output_file_name = f'{safe_model_name}_prompt_{prompt_number}_max_{max_tokens}_temp_{temperature}.xlsx'
                            output_file_path = os.path.join(output_directory, output_file_name)
                            result_df.to_excel(output_file_path, index=False)
                            print(f"Results saved to {output_file_path}")

if __name__ == "__main__":
    main()
